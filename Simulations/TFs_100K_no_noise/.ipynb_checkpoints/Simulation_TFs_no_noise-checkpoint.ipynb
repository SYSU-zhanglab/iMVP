{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5868ff8",
   "metadata": {},
   "source": [
    "## Analyze large simulation dataset by iMVP\n",
    "\n",
    "It is a problem that for most of the situation we will never know what exactly the ground-truth is. Hence it is better for use to use simulated dataset to estimate the performance of iMVP. \n",
    "\n",
    "Different from another `Simulation_TFs.ipynb`, no noise is generated in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c291d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import scipy.stats\n",
    "import tracemalloc\n",
    "import umap\n",
    "import hdbscan\n",
    "import logging\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, adjusted_rand_score\n",
    "logging.captureWarnings(True)\n",
    "# for Linux only, load font file\n",
    "# mpl.font_manager.fontManager.addfont(\"./arial.ttf\")\n",
    "\n",
    "# configure matplotlib\n",
    "# mpl.rcParams['font.family'] = 'Arial'\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b924d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_logos_cols(prefix, names=None, cols=3, figsize=(8,8), auto_size=True):\n",
    "    file_list = []\n",
    "    for img in os.listdir(prefix):\n",
    "        if img.endswith(\".png\") == False:\n",
    "            continue\n",
    "        if names is not None and fn not in names:\n",
    "            continue\n",
    "        file_list.append(img)\n",
    "    \n",
    "    file_list_format = []\n",
    "    for i in file_list:\n",
    "        try:\n",
    "            id = int(i.replace(\"cluster_\", \"\").replace(\".png\", \"\"))\n",
    "        except ValueError:\n",
    "            id = i.replace(\"cluster_\", \"\").replace(\".png\", \"\")\n",
    "        file_list_format.append((i, id))\n",
    "    file_list_format = sorted(file_list_format, key=lambda x:x[1]) \n",
    "    \n",
    "    if len(file_list_format) % cols == 0:\n",
    "        rows = len(file_list_format) // cols\n",
    "    else:\n",
    "        rows = len(file_list_format) // cols + 1\n",
    "    if auto_size == False:\n",
    "        figsize = figsize\n",
    "    else:\n",
    "        width = 4 * cols\n",
    "        height = 1.5 * rows\n",
    "        figsize = (width, height)\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
    "    if len(file_list_format) > 1:\n",
    "        for ax, image in zip(*[axes.reshape(-1), file_list_format]):\n",
    "            fn, id = image\n",
    "            img = plt.imread(prefix+\"/\"+fn)\n",
    "            _ = ax.imshow(img)\n",
    "            ax.set_title(\"{}\".format(id))\n",
    "        for ax in axes.reshape(-1):\n",
    "            ax.axis(\"off\")\n",
    "    else:\n",
    "        image = file_list_format[0]\n",
    "        fn, id = image\n",
    "        img = plt.imread(prefix+\"/\"+fn)\n",
    "        _ = axes.imshow(img)\n",
    "        axes.set_title(\"{}\".format(id))\n",
    "        axes.axis(\"off\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5faf7eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(fn):\n",
    "    # intotal 21 nt\n",
    "    data = {\"TF\":{}, \"motif_F10\": {}}\n",
    "    df_TF = pd.read_csv(fn, index_col=None, header=0)\n",
    "    # TFs = set(df_TF[\"TF\"].tolist())\n",
    "    # num_of_motifs =  [20000, 10000, 8000, 6000, 5000, 4000, 3000, 2000, 1000, 500, 250, 100 ]\n",
    "    simu_dict = {\n",
    "        \"CEBPB\": 10000,\n",
    "        \"ELF1\": 4000,\n",
    "        \"ESR2\":\t2000,\n",
    "        \"FOXA1\": 8000,\n",
    "        \"HAT5\": 20000,\n",
    "        \"HOXA5\":\t500,\n",
    "        \"JUNB\" :\t250,\n",
    "        \"NFKB1\" :\t5000,\n",
    "        \"Pdx1\" :1000,\n",
    "        \"SOX6\" :\t6000,\n",
    "        \"YY1\" : 3000,\n",
    "        \"ZEB1\" :100,\n",
    "    }\n",
    "    basespace = df_TF.columns[0:4]\n",
    "    N = 0\n",
    "    for TF, sim_num in simu_dict.items():\n",
    "        motif_matrix = df_TF[df_TF[\"TF\"] == TF]\n",
    "        right_max = 21 - motif_matrix.shape[0]\n",
    "        # pos = 5\n",
    "        pos = np.random.randint(0, right_max)\n",
    "        all_bases = []\n",
    "        for idx, row in motif_matrix.iterrows():\n",
    "            all_bases.append(np.random.choice(basespace, sim_num, p=row[basespace]/row[basespace].sum()))\n",
    "        for i in zip(*all_bases):\n",
    "            core = \"\".join(i)\n",
    "\n",
    "            left = \"\".join(np.random.choice(basespace, pos)).lower()\n",
    "            right = \"\".join(np.random.choice(basespace, 21 - pos - len(core))).lower()\n",
    "            sim_seq = left + core + right\n",
    "            data[\"TF\"][N] = TF\n",
    "            data[\"motif_F10\"][N] = sim_seq.upper()\n",
    "            N += 1\n",
    "    # noise \n",
    "    #for i in range(50000):\n",
    "    #    data[\"TF\"][N] = \"random_noise\"\n",
    "    #    data[\"motif_F10\"][N] = \"\".join(np.random.choice(basespace, 21))\n",
    "    #    N += 1\n",
    "    return pd.DataFrame(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5fe320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = simulation(\"TFs_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd47a677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>motif_F10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CEBPB</td>\n",
       "      <td>ACACAATATTACACCATGTGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CEBPB</td>\n",
       "      <td>GCTAAACATTGCGTAATGCTT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CEBPB</td>\n",
       "      <td>TCCGTATGTTGCACAATCTTG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CEBPB</td>\n",
       "      <td>AATCCATATTGCATCAGCTAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CEBPB</td>\n",
       "      <td>CCCTCGGGTTTCCCAATCGCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59845</th>\n",
       "      <td>ZEB1</td>\n",
       "      <td>CGAGTTTCTCACACCTGGAGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59846</th>\n",
       "      <td>ZEB1</td>\n",
       "      <td>AAGTGCAACTATACCTGTTCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59847</th>\n",
       "      <td>ZEB1</td>\n",
       "      <td>CTAGCGCTCTACACCTGAGTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59848</th>\n",
       "      <td>ZEB1</td>\n",
       "      <td>AACCTGCAACACACCTGCCAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59849</th>\n",
       "      <td>ZEB1</td>\n",
       "      <td>CCTTTCAGGCTCACCTGTGGA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59850 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          TF              motif_F10\n",
       "0      CEBPB  ACACAATATTACACCATGTGG\n",
       "1      CEBPB  GCTAAACATTGCGTAATGCTT\n",
       "2      CEBPB  TCCGTATGTTGCACAATCTTG\n",
       "3      CEBPB  AATCCATATTGCATCAGCTAG\n",
       "4      CEBPB  CCCTCGGGTTTCCCAATCGCA\n",
       "...      ...                    ...\n",
       "59845   ZEB1  CGAGTTTCTCACACCTGGAGA\n",
       "59846   ZEB1  AAGTGCAACTATACCTGTTCC\n",
       "59847   ZEB1  CTAGCGCTCTACACCTGAGTC\n",
       "59848   ZEB1  AACCTGCAACACACCTGCCAG\n",
       "59849   ZEB1  CCTTTCAGGCTCACCTGTGGA\n",
       "\n",
       "[59850 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72c7b644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>motif_F10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CEBPB</th>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELF1</th>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESR2</th>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOXA1</th>\n",
       "      <td>8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAT5</th>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOXA5</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JUNB</th>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFKB1</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pdx1</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOX6</th>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YY1</th>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZEB1</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       motif_F10\n",
       "TF              \n",
       "CEBPB      10000\n",
       "ELF1        4000\n",
       "ESR2        2000\n",
       "FOXA1       8000\n",
       "HAT5       20000\n",
       "HOXA5        500\n",
       "JUNB         250\n",
       "NFKB1       5000\n",
       "Pdx1        1000\n",
       "SOX6        6000\n",
       "YY1         3000\n",
       "ZEB1         100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"TF\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96b5de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(dtype=np.int8)\n",
    "enc.fit([[i] for i in \"ATCG\"])\n",
    "\n",
    "def onehot_enc(row):\n",
    "    seq = [[i] for i in row[\"motif_F10\"].upper()]\n",
    "    return enc.transform(seq).toarray().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502a1c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_input = []\n",
    "for idx, row in df.iterrows():\n",
    "    onehot_input.append(onehot_enc(row))\n",
    "onehot_input = np.array(onehot_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1affef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_one_sample(ax, df, title=None, cluster_col=\"Cluster\", s=0.2, alpha=1.0):\n",
    "    clusters = list([i for i in range(1, int(df[cluster_col].max())+1)]) + [-1]\n",
    "    \n",
    "    for i in clusters:\n",
    "        subdf = df[df[cluster_col]==i]\n",
    "        if i == -1:\n",
    "            ax.scatter(subdf[\"X\"], subdf[\"Y\"], s=s, alpha=alpha, c=\"lightgray\", lw=None, zorder=0, label=i)\n",
    "        else:\n",
    "            ax.scatter(subdf[\"X\"], subdf[\"Y\"], s=s, alpha=alpha, lw=None, label=i)\n",
    "            c_X = subdf[\"X\"].mean()\n",
    "            c_Y = subdf[\"Y\"].mean()\n",
    "            ax.annotate(\"{}\".format(i), xy=(c_X, c_Y), color=\"k\", ha=\"center\", va=\"center\", size=9) # , size=13\n",
    "\n",
    "    xmin, xmax = ax.get_xlim()\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "\n",
    "    # draw density\n",
    "    xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "    positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "    values = np.vstack([df[\"X\"], df[\"Y\"]])\n",
    "    kernel = scipy.stats.gaussian_kde(values)\n",
    "    f = np.reshape(kernel(positions).T, xx.shape)\n",
    "    c = ax.contour(xx, yy, f, linewidths=0.5, colors=\"k\")\n",
    "\n",
    "    ax.set_xlabel(\"UMAP-1\")\n",
    "    ax.set_ylabel(\"UMAP-2\")\n",
    "    ax.set_title(title)\n",
    "    # ax.xaxis.set_major_locator(ticker.MultipleLocator(3))\n",
    "    # ax.yaxis.set_major_locator(ticker.MultipleLocator(3))\n",
    "    return xmin, xmax, ymin, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UMAP(onehot_input, df, min_dist=0.01, n_neighbors=20, verbose=False, densmap=False, metric='euclidean'):\n",
    "    df = df.copy()\n",
    "    # this should takes ~20 sec   \n",
    "    print(\"UMAP\")\n",
    "    current, _ = tracemalloc.get_traced_memory()\n",
    "    time0 = time.time()\n",
    "    \n",
    "    model = umap.UMAP(init=\"random\", random_state=42, n_components=2, min_dist=min_dist, n_neighbors=n_neighbors, verbose=verbose, densmap=densmap, metric=metric)\n",
    "    umap_output = model.fit_transform(onehot_input)\n",
    "    \n",
    "    time1 = time.time() - time0\n",
    "    _, peak = tracemalloc.get_traced_memory()\n",
    "    \n",
    "    mem = (peak - current)/1024./1024.\n",
    "    \n",
    "    print(\"UMAP time: {} sec\".format(time1))\n",
    "    print(\"UMAP RAM: {} MB\".format(mem))\n",
    "    print(\"==================================================\")\n",
    "    print()\n",
    "    df[\"X\"] = umap_output[:, 0]\n",
    "    df[\"Y\"] = umap_output[:, 1]\n",
    "    \n",
    "    del model\n",
    "    return time1, mem, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993065aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_HDBSCAN(df, min_cluster_size=100, min_samples=10, cluster_selection_epsilon=0.0, cluster_selection_method='eom', draw_condensed_tree=True, soft_clustering=True, optimize=True):\n",
    "    # use multi-code here\n",
    "    df = df.copy()\n",
    "    X = np.stack([df[\"X\"], df[\"Y\"]], axis=1)\n",
    "    current, _ = tracemalloc.get_traced_memory()\n",
    "    time0 = time.time()\n",
    "    model = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size, min_samples=min_samples, cluster_selection_epsilon=cluster_selection_epsilon, cluster_selection_method=cluster_selection_method, core_dist_n_jobs=4, prediction_data=True)\n",
    "    if optimize == True:\n",
    "        validity_scorer = make_scorer(hdbscan.validity.validity_index,greater_is_better=True)\n",
    "        param_dist = {'min_samples': [10, 50,100, 200], # 1,\n",
    "                      'min_cluster_size':[100,200, 300, 500, 1000],  \n",
    "                      'cluster_selection_method' : ['eom'],\n",
    "                     }\n",
    "        n_iter_search = 20\n",
    "        '''\n",
    "        random_search = RandomizedSearchCV(model\n",
    "                                           ,param_distributions=param_dist\n",
    "                                           ,n_iter=n_iter_search\n",
    "                                           ,scoring=validity_scorer \n",
    "                                           ,random_state=42)\n",
    "        '''\n",
    "        grid_search = GridSearchCV(model,param_dist,scoring=validity_scorer)\n",
    "        # random_search.fit(X)\n",
    "        grid_search.fit(X)\n",
    "        # print(random_search.best_params_)\n",
    "        model = grid_search.best_estimator_\n",
    "        print(grid_search.best_estimator_)\n",
    "        # model = random_search.best_estimator_\n",
    "    yhat = model.fit(X)\n",
    "    \n",
    "    if soft_clustering == True:\n",
    "        soft_clusters = hdbscan.all_points_membership_vectors(yhat)\n",
    "        labels = [np.argmax(x) for x in soft_clusters] \n",
    "    else:\n",
    "        labels = yhat.labels_\n",
    "    \n",
    "    time1 = time.time() - time0\n",
    "    _, peak = tracemalloc.get_traced_memory()\n",
    "    mem = (peak - current)/1024./1024.\n",
    "    \n",
    "    df[\"Cluster\"] = [i+1 if i > -1 else -1 for i in labels ]  # re-number lables to make it human-readable\n",
    "    \n",
    "    print(\"HDBSCAN soft clustering time: {} sec\".format(time1))\n",
    "    print(\"HDBSCAN soft clustering RAM: {} Mb\".format(mem))\n",
    "    print(\"HDBSCAN cluster number: {}\".format(df[\"Cluster\"].max()))\n",
    "    print(\"==================================================\")\n",
    "    # check cluster number\n",
    "    print(df.groupby(\"Cluster\")[\"Cluster\"].count())\n",
    "    \n",
    "    \n",
    "    if draw_condensed_tree == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        model.condensed_tree_.plot(select_clusters=True, selection_palette=sns.color_palette())\n",
    "    return time1, mem, df, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c74d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fasta_and_draw_motifs(prefix, df, cluster_col=\"Cluster\", filter=None, motif_column=\"motif_F10\", draw_logos=True):\n",
    "    print(\"===============  {} ===============\".format(prefix))\n",
    "    if os.path.isdir(\"{}\".format(prefix)) == False:\n",
    "        os.mkdir(\"./{}\".format(prefix))\n",
    "        os.mkdir(\"./{}/fasta\".format(prefix))\n",
    "        os.mkdir(\"./{}/logos_bits\".format(prefix))\n",
    "        os.mkdir(\"./{}/logos_bits_no_axis\".format(prefix))\n",
    "        os.mkdir(\"./{}/logos_freq\".format(prefix))\n",
    "        os.mkdir(\"./{}/logos_freq_png\".format(prefix))\n",
    "        os.mkdir(\"./{}/logos_bits_png\".format(prefix))\n",
    "    else:\n",
    "        os.system(\"rm -r ./{}/*\".format(prefix))\n",
    "        os.mkdir(\"./{}/fasta\".format(prefix))\n",
    "        os.mkdir(\"./{}/logos_bits\".format(prefix))\n",
    "        os.mkdir(\"./{}/logos_bits_no_axis\".format(prefix))\n",
    "        os.mkdir(\"./{}/logos_freq\".format(prefix))\n",
    "        os.mkdir(\"./{}/logos_freq_png\".format(prefix))\n",
    "        os.mkdir(\"./{}/logos_bits_png\".format(prefix))\n",
    "    if filter is not None:\n",
    "        df = df[df[filter] == True].copy()\n",
    "    clusters = set(df[cluster_col].tolist())\n",
    "    for g in clusters:\n",
    "        subdf = df[df[cluster_col] == g]\n",
    "        with open(\"./{}/fasta/cluster_{}.fa\".format(prefix, g), \"w\") as output:\n",
    "            N = 0\n",
    "            for idx, row in subdf.iterrows():\n",
    "                output.write(\">{}\\n{}\\n\".format(idx, row[motif_column]))  # to RNA bases .replace(\"T\", \"U\")\n",
    "                N += 1\n",
    "            print(\"Cluster #{}: {}\".format(g, N))\n",
    "    if draw_logos == True:\n",
    "        for g in clusters:\n",
    "            os.system(\"weblogo -A dna -D fasta -F pdf --resolution 1000 --color-scheme classic --composition none -i 0 -P \\\"\\\" -f ./{prefix}/fasta/cluster_{g}.fa -o ./{prefix}/logos_bits/cluster_{g}.pdf\".format(prefix=prefix, g=g))\n",
    "            \n",
    "            os.system(\"weblogo -A dna -D fasta -F png --resolution 1000 --color-scheme classic --composition none -i 0 -P \\\"\\\" -f ./{prefix}/fasta/cluster_{g}.fa -o ./{prefix}/logos_bits_png/cluster_{g}.png\".format(prefix=prefix, g=g))\n",
    "\n",
    "            os.system(\"weblogo -A dna -D fasta -F pdf -y Frequency --resolution 1000 --color-scheme classic --units probability --composition none -i 0 -P \\\"\\\" -f ./{prefix}/fasta/cluster_{g}.fa -o ./{prefix}/logos_freq/cluster_{g}.pdf\".format(prefix=prefix, g=g))\n",
    "            \n",
    "            os.system(\"weblogo -A dna -D fasta -F png -y Frequency --resolution 1000 --color-scheme classic --units probability --composition none -i 0 -P \\\"\\\" -f ./{prefix}/fasta/cluster_{g}.fa -o ./{prefix}/logos_freq_png/cluster_{g}.png\".format(prefix=prefix, g=g)) \n",
    "            \n",
    "            os.system(\"weblogo -A dna -D fasta -X no -Y no -P \\\"\\\" -F pdf --resolution 1000 --color-scheme classic --composition none -i 0 -f ./{prefix}/fasta/cluster_{g}.fa -o ./{prefix}/logos_bits_no_axis/cluster_{g}.pdf\".format(prefix=prefix, g=g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9d800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, df_UMAP = UMAP(onehot_input, df, min_dist=0.01, n_neighbors=20, verbose=False, densmap=False, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33453cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UMAP.to_csv(\"Sim_UMAP.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc3af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=sns.color_palette(\"Paired\")) \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for TF in set(df_UMAP[\"TF\"].tolist()):\n",
    "    if TF != \"random_noise\":\n",
    "        subdf = df_UMAP[df_UMAP[\"TF\"] == TF]\n",
    "        ax.scatter(subdf[\"X\"], subdf[\"Y\"], s=3, label=TF)\n",
    "    else:\n",
    "        subdf = df_UMAP[df_UMAP[\"TF\"] == TF]\n",
    "        ax.scatter(subdf[\"X\"], subdf[\"Y\"], s=3, label=TF, zorder=0, color=\"lightgray\")\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ymin, ymax = ax.get_ylim()\n",
    "xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "values = np.vstack([df_UMAP[\"X\"], df_UMAP[\"Y\"]])\n",
    "kernel = scipy.stats.gaussian_kde(values)\n",
    "f = np.reshape(kernel(positions).T, xx.shape)\n",
    "c = ax.contour(xx, yy, f, linewidths=0.5, colors=\"k\")\n",
    "    \n",
    "ax.set_xlabel(\"UMAP-1\")\n",
    "ax.set_ylabel(\"UMAP-2\")\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"UMAP-ground_truth.jpg\", dpi=300)\n",
    "plt.legend()\n",
    "plt.savefig(\"UMAP-ground_truth.legend.jpg\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e889f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #_, _, df_HDBSCAN, _ = cluster_HDBSCAN(df_UMAP, min_cluster_size=100, min_samples=100, soft_clustering=False, optimize=True)\n",
    "_, _, df_HDBSCAN, _ = cluster_HDBSCAN(df_UMAP, min_cluster_size=100, min_samples=100, soft_clustering=False, optimize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9746a036",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "draw_one_sample(ax, df_HDBSCAN, title=None, cluster_col=\"Cluster\")\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"iMVP_out.jpg\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9155a663",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sim_out.fa\", \"w\") as output:\n",
    "    for idx, row in df.iterrows():\n",
    "        output.write(\">{}_{}\\n{}\\n\".format(row[\"TF\"], idx, row[\"motif_F10\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eac3843",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_fasta_and_draw_motifs(\"iMVP_out\", df_HDBSCAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0664b9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_logos_cols(\"./iMVP_out/logos_bits_png/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a4d01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_fasta_and_draw_motifs(\"iMVP_out_ground_truth\", df_HDBSCAN, cluster_col=\"TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d92a414",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_logos_cols(\"./iMVP_out_ground_truth/logos_bits_png/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5594e83",
   "metadata": {},
   "source": [
    "## HDBSCAN (not softclustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259ac26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, df_HDBSCAN_soft, _ = cluster_HDBSCAN(df_UMAP, min_cluster_size=100, min_samples=100, soft_clustering=True, optimize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e7c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "draw_one_sample(ax, df_HDBSCAN_soft, title=None, cluster_col=\"Cluster\")\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"iMVP_out.soft.jpg\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f01cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_fasta_and_draw_motifs(\"iMVP_out_soft\", df_HDBSCAN_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_logos_cols(\"./iMVP_out_soft/logos_bits_png/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d46c352",
   "metadata": {},
   "source": [
    "## Leiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4e3400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap.umap_ import nearest_neighbors\n",
    "from scipy.sparse import issparse, coo_matrix, csr_matrix\n",
    "# leiden\n",
    "import leidenalg\n",
    "import igraph as ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04215e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparse_matrix_from_indices_distances_umap(\n",
    "        knn_indices, knn_dists, n_obs, n_neighbors\n",
    "    ):\n",
    "    from scipy.sparse import issparse, coo_matrix, csr_matrix\n",
    "    rows = np.zeros((n_obs * n_neighbors), dtype=np.int64)\n",
    "    cols = np.zeros((n_obs * n_neighbors), dtype=np.int64)\n",
    "    vals = np.zeros((n_obs * n_neighbors), dtype=np.float64)\n",
    "\n",
    "    for i in range(knn_indices.shape[0]):\n",
    "        for j in range(n_neighbors):\n",
    "            if knn_indices[i, j] == -1:\n",
    "                continue  # We didn't get the full knn for i\n",
    "            if knn_indices[i, j] == i:\n",
    "                val = 0.0\n",
    "            else:\n",
    "                val = knn_dists[i, j]\n",
    "\n",
    "            rows[i * n_neighbors + j] = i\n",
    "            cols[i * n_neighbors + j] = knn_indices[i, j]\n",
    "            vals[i * n_neighbors + j] = val\n",
    "\n",
    "    result = coo_matrix((vals, (rows, cols)), shape=(n_obs, n_obs))\n",
    "    result.eliminate_zeros()\n",
    "    return result.tocsr()\n",
    "\n",
    "def compute_connectivities_umap(\n",
    "        knn_indices,\n",
    "        knn_dists,\n",
    "        n_obs,\n",
    "        n_neighbors,\n",
    "        set_op_mix_ratio=1.0,\n",
    "        local_connectivity=1.0,\n",
    "    ):\n",
    "    from scipy.sparse import issparse, coo_matrix, csr_matrix\n",
    "    from umap.umap_ import fuzzy_simplicial_set\n",
    "    X = coo_matrix(([], ([], [])), shape=(n_obs, 1))\n",
    "    connectivities = fuzzy_simplicial_set(\n",
    "        X,\n",
    "        n_neighbors,\n",
    "        None,\n",
    "        None,\n",
    "        knn_indices=knn_indices,\n",
    "        knn_dists=knn_dists,\n",
    "        set_op_mix_ratio=set_op_mix_ratio,\n",
    "        local_connectivity=local_connectivity,\n",
    "    )\n",
    "\n",
    "    if isinstance(connectivities, tuple):\n",
    "        # In umap-learn 0.4, this returns (result, sigmas, rhos)\n",
    "        connectivities = connectivities[0]\n",
    "\n",
    "    distances = get_sparse_matrix_from_indices_distances_umap(\n",
    "        knn_indices, knn_dists, n_obs, n_neighbors\n",
    "    )\n",
    "\n",
    "    return distances, connectivities.tocsr()\n",
    "\n",
    "def get_igraph_from_adjacency(adjacency, directed=None):\n",
    "    \"\"\"Get igraph graph from adjacency matrix.\"\"\"\n",
    "    sources, targets = adjacency.nonzero()\n",
    "    weights = adjacency[sources, targets]\n",
    "    if isinstance(weights, np.matrix):\n",
    "        weights = weights.A1\n",
    "    g = ig.Graph(directed=directed)\n",
    "    g.add_vertices(adjacency.shape[0])  # this adds adjacency.shape[0] vertices\n",
    "    g.add_edges(list(zip(sources, targets)))\n",
    "    try:\n",
    "        g.es['weight'] = weights\n",
    "    except KeyError:\n",
    "        pass\n",
    "    return g\n",
    "\n",
    "def get_igraph(onehot_input, random_state = 42, metric=\"euclidean\", n_neighbors = 20, metric_kwds={}, angular=False, verbose=False):\n",
    "    time0 = time.time()\n",
    "    n_obs = onehot_input.shape[0]\n",
    "    \n",
    "    knn_indices, knn_dists, forest = nearest_neighbors(\n",
    "            onehot_input,\n",
    "            n_neighbors,\n",
    "            random_state=random_state,\n",
    "            metric=metric,\n",
    "            metric_kwds=metric_kwds,\n",
    "            angular=angular,\n",
    "            verbose=verbose,\n",
    "            n_jobs=4,\n",
    "        )\n",
    "      \n",
    "    distances, connectivities = compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio=1.0, local_connectivity=1.0)\n",
    " \n",
    "    g = get_igraph_from_adjacency(connectivities)\n",
    "    return g, time.time() - time0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccd0a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_Leiden(df, graph, resolution_parameter=1):\n",
    "    df = df.copy()\n",
    "    tracemalloc.start()\n",
    "    current, _ = tracemalloc.get_traced_memory()\n",
    "    time0 = time.time()\n",
    "    partition_type = leidenalg.RBConfigurationVertexPartition\n",
    "    model = leidenalg.find_partition(graph, partition_type, seed=42, resolution_parameter=resolution_parameter)\n",
    "    labels = model.membership\n",
    "    \n",
    "    time1 = time.time() - time0\n",
    "    _, peak = tracemalloc.get_traced_memory()\n",
    "    mem = (peak - current)/1024./1024.\n",
    "    tracemalloc.stop()\n",
    "    print(\"Louvain time: {} sec\".format(time1))\n",
    "    print(\"Louvain RAM: {} Mb\".format(mem))\n",
    "    print(\"==================================================\")\n",
    "    print()\n",
    "    \n",
    "    df[\"Cluster\"] = labels\n",
    "    df[\"Cluster\"] += 1\n",
    "    return time1, mem, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3208dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "g, time_graph = get_igraph(onehot_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b6352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1, m1, df_leiden = cluster_Leiden(df_UMAP, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ac7e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_one_sample2(ax, df, title=None, cluster_col=\"Cluster\", s=0.2, alpha=1.0, init=1):\n",
    "    clusters = list([i for i in range(init, int(df[cluster_col].max())+1)]) + [-1]\n",
    "    print(clusters)\n",
    "    for i in clusters:\n",
    "        subdf = df[df[cluster_col]==i]\n",
    "        print(subdf.shape)\n",
    "        if i == -1:\n",
    "            ax.scatter(subdf[\"X\"], subdf[\"Y\"], s=s, alpha=alpha, c=\"lightgray\", lw=None, label=i)\n",
    "        else:\n",
    "            ax.scatter(subdf[\"X\"], subdf[\"Y\"], s=s, alpha=alpha, lw=None, label=i)\n",
    "            c_X = subdf[\"X\"].mean()\n",
    "            c_Y = subdf[\"Y\"].mean()\n",
    "            ax.annotate(\"{}\".format(i), xy=(c_X, c_Y), color=\"k\", ha=\"center\", va=\"center\", size=9) # , size=13\n",
    "\n",
    "    xmin, xmax = ax.get_xlim()\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "\n",
    "    # draw density\n",
    "    xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "    positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "    values = np.vstack([df[\"X\"], df[\"Y\"]])\n",
    "    kernel = scipy.stats.gaussian_kde(values)\n",
    "    f = np.reshape(kernel(positions).T, xx.shape)\n",
    "    c = ax.contour(xx, yy, f, linewidths=0.5, colors=\"k\")\n",
    "\n",
    "    ax.set_xlabel(\"UMAP-1\")\n",
    "    ax.set_ylabel(\"UMAP-2\")\n",
    "    ax.set_title(title)\n",
    "    # ax.xaxis.set_major_locator(ticker.MultipleLocator(3))\n",
    "    # ax.yaxis.set_major_locator(ticker.MultipleLocator(3))\n",
    "    return xmin, xmax, ymin, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70827b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=sns.color_palette(\"Paired\")) \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "draw_one_sample2(ax, df_leiden, title=None, cluster_col=\"Cluster\", init=0)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"iMVP_out.leiden.jpg\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2628cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_fasta_and_draw_motifs(\"iMVP_out_leiden\", df_leiden, cluster_col=\"Cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e4582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_logos_cols(\"./iMVP_out_leiden/logos_bits_png/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d50655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    \"CEBPB\": 1,\n",
    "    \"ELF1\": 2,\n",
    "    \"ESR2\":\t3,\n",
    "    \"FOXA1\": 4,\n",
    "    \"HAT5\": 5,\n",
    "    \"HOXA5\":\t6,\n",
    "    \"JUNB\" :\t7,\n",
    "    \"NFKB1\" :\t8,\n",
    "    \"Pdx1\" :9,\n",
    "    \"SOX6\" :\t10,\n",
    "    \"YY1\" : 11,\n",
    "    \"ZEB1\" :12,\n",
    "    \"random_noise\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6239e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_ARI(df, name):\n",
    "    # firstly, get confusion matrix\n",
    "    exp_values = []\n",
    "    for i in df[\"TF\"]:\n",
    "        exp_values.append(label_dict[i])\n",
    "    pred_values = []\n",
    "    for i in df[\"Cluster\"]:\n",
    "        pred_values.append(i)\n",
    "    ARI = adjusted_rand_score(exp_values, pred_values)\n",
    "    print(name, ARI)\n",
    "    return ARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ce7759",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_ARI(df_HDBSCAN, \"HDBSCAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742911ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_ARI(df_HDBSCAN_soft, \"HDBSCAN soft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ce7b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_ARI(df_leiden, \"Leiden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b260c92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
